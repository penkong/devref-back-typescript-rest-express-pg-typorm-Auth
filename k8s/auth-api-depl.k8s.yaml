# deployment bluprint for scale with defined service(IP static) + pod  <--- configMap env var + secret

# for things that have states like database , there is component do same as deployment and it contain
# named SatefulSet
# there fore it is better to DB host outside of k8s cluster . let them replicated easier in kluster
# it is better all cluster be stateless

# each worker node get 3 process , runtime container (docker) , kubelet the process that schedule pods containers and ...
# kubelet has interface with container and Node at same time , kubelet take config and start pod it define resources also
# Nodes (physical seprated machine) communicate with services
# 3th process kube proxy is responsible to forwarding request from service to pod , prevent bad network communication
#
# Master  node, when nodes become cluster we need schedule pods accross nodes , monitoring , re-schedule restart , join new node and ...
# there are 4 process on master node .
#
# first Api server , u as deployer and developer send update/req/query to it , cluster gateway , gate keeper for authentication
# dispatcher to other procesess
#
# second Scheduler , api server hand request to scheduler . decsion on where to put pod on any node it talk with kubelet on node
#
# third Control Manager , detect died pod dying , detect change of states send request to scheduler
#
# forth etcd , key values store of cluster states , cluster brain , changes save to it .

# each computer that has all processes(4 or 3) can be Master or Worker node .

# minikube for local  master and worker are at same place
# minikube create virtual box and add porcess for run  a node to it. minikube is cluster

# kubectl for interaction . is part of Api Server
#
# kubectl create deployment nginx-depl --image=nginx
# k get deployment
# k get replicaset

# deployment manage replica set , replica set manage a pod , pod is abstraction of container
# kubectl edit deplyment nginx-depl --> get auto generated config

# debug
# kubectl logs name
# kubectl describe pod nanme
# kubectl exec -it <>pod bash
# kubectl describe service
# kubectl get pod -o wide
# kubectl get deployment name -o yaml $$$$$$$$$$$$$$$$$$$$$$$$$$$$
# k get all | grep <name>
# minikube docker-env

# with file
# kubectl apply -f filename

#  config files
#  1.metadata
#  2.specification , config , attribute of spcific about that kind
#  kinds are in apiVersion
#  3.status , auto generated by k8s , desired state =vs= actual state stored in etcd
#  yaml

# metadatas section contain labels =vs= spec part contain selector
# use for connection between deployment and pod
# first meta data in deployment use by service selector to select
#
#
#
# Namspaces : orgize resources in namespaces
#   virtual cluster inside a cluster
#   there are 4 namespaces by default
#   k get namespace
#   k-dashboard is for minikube only
#   k-system not for your use (system process , managing process)
#   k-public publicely accssible data , a configmap , which contains cluster info
#      k cluster-info
#   k-node-lease contain heartbeat of nodes , each node has associated lease Object in namespace
#   k-default , if you don't define one all your things containers add in this
# can create namespace from termina and config map
# use namespaceing for isolation , sepration , database namespace , monitor namespac , elastic .
#  nginx-ingress namespace or for each env , staging , development and ... or 2 production version
#  also use for limit resources / env
#  each namespace must define own ConfigMap and other namespace cant use other namespace configMap
#  service can be shared accross namespaces
#  use database service from namespace database in configmap of controllers it become db_url:mysqlService.databaseNamespace

#  volume and Node are global access in cluster
#  k api-resources --namespaced=false

#  k get configmap -n default
#  k apply -f file.k8s.yaml --namespace=specific or add to config

# kubens for namespace
#  https://github.com/ahmetb/kubectx/releases
#  Install kubectx (Switch between Kubernetes contexts/namespaces)
#  sudo curl -sSL http://github.com/ahmetb/kubectx/archive/v0.3.1.tar.gz | tar -C /usr/local/ -xz
#  export PATH=/usr/local/kubectx-0.3.1:$PATH

# ----------------

#  Ingress
#  ingress controller pod >> (browser)ingress(routing) >> app serivce >> app pod
#
#   make ingress config , then need ingres controller pod to add and install
#   ingress controller manage and redirects , entry point to cluster
#   minikube addons enable ingress
#   k get pod -n kube-system , k describe deploy ingress-nginx-controller -n kube-system
#   map with /etc/hosts
#
#   minikube addons enable ingress --alsologtostderr
#
#
#
#   Helm :
#   what is helm ? package manager , to package yaml files
#   consider want add elastik
#   you create Helm charts , bundle of yaml files , bootstraper of functionality
#   create helm chart with helm , databases have helm chart available
#   helm search <keyword > or helm hub or helm charts
#   also helm is templating engine , consider microservices that are same only app name and version are
#   different , define a commin blueprint and it gave us syntsx {{ .Values.name }} and it come from values.yaml for ex
#   useful with ci/cd and same app across different env or Nodes use your own charts for different env
#
#
#   Persistant volume , persistant volume claim , storage class
#
#   pv  s are cluster resources like ram and cpu
#   create with yaml file kind: PersistanVolume
#   pv is abstract component and need real storage on physical .
#   you need to know what type of storage you need
#   storage are external plugin in kuber cluster
#
#   pv are not namespaced they can access by whole cluster
#   developer --> pod --> pvc (we claim for that remote pv) --> pv
#   pvc are namespaced
#   develpers pvc , admins pv
#   also we have 2 volume type config map and secret (not created by pv or pvc)

#   on real world need a lot pv , admin
#   storage class provisions  pv dynamically (abstract underlying storage provider)

#  stateful set , for statful application like sql and ...
#  stateless deployed using Deployment
#  stateful deployed using StatefulSet
#  in stateful replica pods are not identical pod identity
#  master pod and slave pod , master read write , slvae rad  also each one has it's own storage
#  those storeage sync togehter

# https://gitlab.com/gitlab-org/kubernetes-gitlab-demo/-/tree/master/gitlab
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-api-depl
  labels:
    app: auth-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: auth-api
  template:
    metadata:
      labels:
        app: auth-api
    spec:
      containers:
        - name: auth-api
          image: 'penkong/starter2:latest'
          imagePullPolicy: Always
          env:
            - name: NODE_ENV
              # value: development
              valueFrom:
                configMapKeyRef:
                  name: dbpg-confmap
                  key: dev

            - name: DB
              # value: postgres
              valueFrom:
                configMapKeyRef:
                  name: dbpg-confmap
                  key: dbdriver

            - name: DBNAME
              # value: devrefauth
              valueFrom:
                configMapKeyRef:
                  name: dbpg-confmap
                  key: dbname

            - name: DB_DOCKER
              # value: dbpg-srv
              valueFrom:
                configMapKeyRef:
                  name: dbpg-confmap
                  key: dbdocker

            - name: DB_URL
              value: hfsdfdsf

            - name: PGUSER
              # value: root
              valueFrom:
                secretKeyRef:
                  name: dbpg-sec
                  key: rootPgUser

            - name: PASSWORD
              # value: secret
              valueFrom:
                secretKeyRef:
                  name: dbpg-sec
                  key: rootPgPass

            - name: PORT
              value: '5003'

              # valueFrom:
              #   configMapKeyRef:
              #     name: dbpg-confmap
              #     key: apiport
            - name: CORS
              # value: fdsfdsfds
              valueFrom:
                configMapKeyRef:
                  name: dbpg-confmap
                  key: cors

            - name: JWT_KEY
              # value: dsfsdfsdfsdfsdf
              valueFrom:
                secretKeyRef:
                  name: dbpg-sec
                  key: jwtkey

            - name: JWT_TTL
              # value: 365d
              valueFrom:
                secretKeyRef:
                  name: dbpg-sec
                  key: jwtttl

          resources:
            limits:
              memory: '256Mi'
              cpu: '500m'
          ports:
            - containerPort: 5003

---
apiVersion: v1
kind: Service
metadata:
  name: auth-api-srv
spec:
  # type: LoadBalancer
  selector:
    app: auth-api
  ports:
    - protocol: TCP
      port: 5003
      targetPort: 5003
      # nodePort: 31887
